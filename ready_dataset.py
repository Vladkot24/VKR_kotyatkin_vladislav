# -*- coding: utf-8 -*-
"""Ready_dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CI84qE1iD19AwESPzZGO14ZzuiEUqEZU

**Подготовка датасета для дальнейшего обучения модели**

Установка и импорт библиотек
"""

!pip install pandas pyarrow fastparquet

import pandas as pd
import glob
import random
import re
import os

from google.colab import drive
drive.mount('/content/drive')

"""Загружаем 50 случайных файлов и берем из каждого по 1500 строк"""

# Путь к папке с parquet-файлами
dataset_path = '/content/drive/MyDrive/Dataset/'

# Получаем список всех parquet-файлов
parquet_files = glob.glob(dataset_path + '*.parquet')

# Выбираем 50 случайных файлов
sampled_files = random.sample(parquet_files, 50)

# Считываем по 1500 случайных строк из каждого файла
df_list = []
for file in sampled_files:
    df_part = pd.read_parquet(file, engine='pyarrow')
    sampled_rows = df_part.sample(n=min(1500, len(df_part)), random_state=42)
    df_list.append(sampled_rows)

# Объединяем всё в один датафрейм
df = pd.concat(df_list, ignore_index=True)

"""ОЧИСТКА ОТ ПУСТЫХ И НЕНУЖНЫХ СТРОК"""

df.head()

df.info()

# Удаляем строки с пропущенными значениями в ключевых колонках
df = df.dropna(subset=['text_2', 'text_3'])

#  нас инетерсует суть дела и судебное решение
df['input_text'] = df['text_2'].str.strip()
df['target_text'] = df['text_3'].str.strip()

# Оставляем только нужные колонки
df = df[['input_text', 'target_text']]

"""УДАЛЕНИЕ НЕПОНЯТНЫХ СИМВОЛОВ И АНГЛИЙСКИХ СЛОВ"""

# Удаляем строки, где в input или target содержатся символы латиницы
pattern = re.compile(r'[a-zA-Z]')
df = df[~df['input_text'].str.contains(pattern)]
df = df[~df['target_text'].str.contains(pattern)]

"""ОЧИСТКА ОТ МУСОРА: ДАТЫ, НОМЕРА ДЕЛ, СИМВОЛЫ"""

def clean_text(text):
    # Удаление переносов строк и лишних пробелов
    text = re.sub(r'\s+', ' ', text)
    # Удаление дат (в формате дд.мм.гггг или дд/мм/гггг)
    text = re.sub(r'\b\d{1,2}[./-]\d{1,2}[./-]\d{2,4}\b', '', text)
    # Удаление номера дела: № и сочетания типа "2-802/2015"
    text = re.sub(r'№\s*\S+|\b\d+-\d+/\d+\b', '', text)
    # Удаление символов, не несущих смысловой нагрузки
    text = re.sub(r'[^\w\sа-яА-Я.,:;!?]', '', text)
    # Удаление лишних пробелов повторно
    text = re.sub(r'\s{2,}', ' ', text).strip()
    return text

df['input_text'] = df['input_text'].apply(clean_text)
df['target_text'] = df['target_text'].apply(clean_text)

from google.colab import drive
drive.mount('/content/drive')

"""СОХРАНЕНИЕ CSV НА ГУГЛ ДИСК И ЛОКАЛЬНО"""

df.info()

df['input_tokens'] = df['input_text'].apply(lambda x: len(x.split()))
df['target_tokens'] = df['target_text'].apply(lambda x: len(x.split()))

# Среднее количество токенов
print(f"Среднее количество токенов в input_text: {df['input_tokens'].mean()}")
print(f"Среднее количество токенов в target_text: {df['target_tokens'].mean()}")

# Сохраняем на Google Диск
output_path_drive = '/content/drive/MyDrive/cleaned_legal_dataset.csv'
df.to_csv(output_path_drive, index=False, encoding='utf-8-sig')
print(f"Сохранено на Google Диск: {output_path_drive}")

